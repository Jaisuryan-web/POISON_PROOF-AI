# PoisonProof AI â€” Dataset Integrity Verification System

PoisonProof AI is a modern Flask web app that helps you assess dataset integrity for AI/ML workflows. It provides:
- A clean Bootstrap 5 UI for uploading CSV or image datasets
- Real anomaly identification for tabular CSVs (robust statistics) and images (digital forensics heuristics)
- SHAâ€‘256 hashing for dataset fingerprinting
- Visual summaries via Plotly charts

This README walks you from installing uv (fast Python package manager) to running and using the app, and then dives deep into how anomalies are detected with examples.

## ðŸš€ Features

- Modern, responsive UI (Bootstrap 5, icons, toasts, progress indicators)
- CSV and image upload (CSV, PNG, JPG, JPEG, GIF, BMP)
- Real anomaly detection:
  - CSV: robust z-scores (MAD) + IQR outlier fences with per-row aggregation
  - Images: Error Level Analysis (ELA), blur/texture (gradient variance), and dynamic range checks
- SHAâ€‘256 hashing of uploaded file for integrity
- Results page with severity-coded table, copyable hash, and a Plotly pie chart

## ðŸ› ï¸ Technology Stack

- Backend: Flask
- Frontend: HTML5, Bootstrap 5, JavaScript
- Data: Pandas, NumPy, Pillow (PIL)
- Charts: Plotly.js

## ðŸ“‹ Prerequisites

- Python 3.10+ (Python 3.12 supported)
- pip (Python package installer)
- uv (recommended for super-fast installs)

## ðŸ”§ Installation with uv (Windows PowerShell)

1) Install/upgrade pip and uv
```powershell
python -m pip install --upgrade pip
python -m pip install uv
uv --version
```

2) Create and activate a virtual environment
```powershell
uv venv .venv
.\.venv\Scripts\Activate.ps1
```

3) Install dependencies from requirements.txt (Python 3.12-friendly)
```powershell
# If you are on Python 3.12, ensure requirements have:
#   numpy>=1.26,<3.0 and pandas>=2.2,<3.0
uv pip install -r requirements.txt
```

Alternative: pyproject workflow (optional)
```powershell
uv init --app
uv add flask==2.3.3 werkzeug==2.3.7 pillow==10.0.1 plotly==5.17.0
uv add "numpy>=1.26,<3.0" "pandas>=2.2,<3.0"
uv sync
uv run python run.py
```

## â–¶ï¸ Quick start

1) Start the app
```powershell
uv run -r requirements.txt python run.py
```

2) Access the app
Open your browser to: `http://127.0.0.1:5000`

3) Generate a big dataset (optional, for a rich demo)
```powershell
uv run -r requirements.txt python generate_large_dataset.py
```
This creates `large_employee_dataset.csv` (1000 rows, ~75 anomalies) in the project root.

4) Upload a file
- Go to â€œScan Datasetâ€ in the navbar.
- Drag-and-drop `large_employee_dataset.csv` (or your own CSV) or upload an image (PNG/JPG/etc.).
- A modal spinner appears while scanning; the file is hashed and analyzed, then deleted from disk.

5) View results
- Anomalies appear in a color-coded table (severity and confidence).
- The SHAâ€‘256 hash can be copied to clipboard.
- A Plotly pie chart shows the severity distribution.

## ðŸ“ Project structure

```
PoisonProof-AI/
â”œâ”€â”€ app.py                  # Flask app + detection logic
â”œâ”€â”€ config.py               # Settings (upload size, extensions, envs)
â”œâ”€â”€ run.py                  # Entry point (uv/pip/python friendly)
â”œâ”€â”€ generate_large_dataset.py# Create a 1000-row CSV with injected anomalies
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ templates/              # Jinja templates (Bootstrap UI)
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ index.html          # Landing page
â”‚   â”œâ”€â”€ upload.html         # Upload form + loading modal
â”‚   â””â”€â”€ results.html        # Results (table + chart + hash)
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/style.css       # Custom styles
â”‚   â””â”€â”€ js/main.js          # UI helpers, toasts, animations
â”œâ”€â”€ uploads/                # Temp storage (auto-cleaned)
â”œâ”€â”€ large_employee_dataset.csv (generated)
â””â”€â”€ README.md
```

## ðŸ§  How anomaly detection works

The app performs lightweight, real anomaly identification without heavy ML dependencies.

### A) CSV datasets (tabular)

We analyze only numeric columns using two robust statistical methods and then aggregate anomalies per row:

1) Robust z-score via MAD (Median Absolute Deviation)
   - For a numeric series x:
     - Median: m = median(x)
     - MAD: mad = median(|x - m|)
     - Robust z: rz = 0.6745 * (x - m) / mad  (0.6745 scales MAD to ~std)
   - We flag values with |rz| > 3.5 as strong outliers.

2) IQR fences (Interquartile Range)
   - q1 = 25th percentile, q3 = 75th percentile, iqr = q3 - q1
   - Lower fence = q1 - 1.5*iqr, Upper fence = q3 + 1.5*iqr
   - Values outside these fences are flagged.

3) Row aggregation and scoring
   - For each numeric column: if a cell is flagged by either method, its magnitude contributes to that rowâ€™s score.
   - Rows are sorted by total anomaly score; up to 50 highest rows are reported.
   - Severity is High if any column is very extreme (e.g., |rz| > 5), Medium for moderate extremes, else Low.
   - Confidence grows with magnitude and the number of flagged columns in the row.

Example (CSV)

Suppose a salary column has mostly values around 60,000â€“120,000, but one entry is 900,000. The median and MAD will be stable despite outliers, so the robust z-score for 900,000 is very large (|rz| >> 3.5), making it a High severity anomaly with high confidence. If that same row also has an impossible performance score (e.g., 11.5 on a 0â€“10 scale), the row score increases and the row becomes a top finding.

Tuning knobs (in `app.py`)
- Threshold for |rz| (default 3.5)
- IQR factor (default 1.5)
- Max reported findings (default 50)

Where to look: functions `_robust_z_score`, `_iqr_bounds`, `_detect_csv_anomalies`.

### B) Image datasets

We use three simple, effective heuristics:

1) Error Level Analysis (ELA)
   - Convert original to JPEG (qualityâ‰ˆ90), then compute the pixel-wise difference between original and recompressed images.
   - Edited regions often recompress differently, yielding higher local differences.
   - We use the mean difference (ELA score) as a global signal; a high mean suggests edits or heavy recompression.

2) Blur/Texture via gradient variance
   - Convert to grayscale, compute finite differences in x/y, take gradient magnitude, then compute its variance.
   - Low variance indicates little edge/texture energy â†’ possibly blurred or low-detail images.

3) Dynamic range
   - If max(gray) - min(gray) is very small, the image might be washed out or overly compressed.

Example (Image)

If you upload an image that has been locally airbrushed to remove text, the ELA score often increases because the touched-up region recompresses differently. The system will flag a â€œVisual Manipulationâ€ with Medium or High severity depending on the score. If the image is also very blurry, you may see an additional â€œImage Qualityâ€ finding.

Tuning knobs (in `app.py`)
- ELA mean threshold (default 12.0; >20 is High)
- Blur threshold on gradient variance (default <25.0)
- Dynamic range threshold (default <30.0)

Where to look: function `_analyze_image`.

## ðŸ§ª Using the application step-by-step

1) Generate a large CSV (optional)
```powershell
uv run -r requirements.txt python generate_large_dataset.py
```
This creates `large_employee_dataset.csv` with realistic distributions and ~75 injected anomalies (e.g., negative salaries, impossible scores, extreme overtime, age/experience mismatches).

2) Start the server
```powershell
uv run -r requirements.txt python run.py
```

3) Upload and scan
- Visit `http://127.0.0.1:5000` â†’ â€œScan Datasetâ€
- Drop `large_employee_dataset.csv` or any image file
- Wait for the modal spinner to finish (files are deleted after processing)

4) Read the results
- Severity badges (High/Medium/Low) indicate urgency
- Confidence indicates strength of evidence
- Copy the SHAâ€‘256 hash and store it for later integrity verification
- The Plotly chart displays the severity distribution of findings

## ðŸ› ï¸ Troubleshooting (Windows, Python 3.12)

Symptom: `uv add -r requirements.txt` fails building numpy 1.24.x with `ModuleNotFoundError: distutils`.

Cause: Python 3.12 removed distutils; old numpy/pandas rely on it. Fix by using 3.12â€‘compatible versions:
- `numpy >= 1.26`
- `pandas >= 2.2`

Solutions:
```powershell
# If using requirements.txt, ensure the ranges are updated, then:
uv pip install -r requirements.txt

# Or explicitly add compatible versions in a pyproject workflow:
uv add "numpy>=1.26,<3.0" "pandas>=2.2,<3.0"
uv sync
```

Other tips:
- If Plotly imports warn in your editor, ensure Plotly is installed in the active venv.
- If a CSV has no numeric columns, the CSV detector will return no anomalies.
- Very small images may bypass blur/ELA thresholds; try higher resolution for better signals.

## ðŸ”’ Security

- Filenames are sanitized (`secure_filename`), types are validated, and max upload size is enforced
- Files are deleted after processing to minimize exposure
- Use a strong `SECRET_KEY` in production (via environment variable)

On Windows PowerShell, set environment variables like:
```powershell
$env:FLASK_ENV = "production"
$env:SECRET_KEY = "your-secure-secret-key"
python run.py
```

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/YourFeature`
3. Commit changes: `git commit -m "feat: add YourFeature"`
4. Push branch: `git push origin feature/YourFeature`
5. Open a Pull Request

## ðŸ“„ License

MIT â€” see [LICENSE](LICENSE)

## ðŸ“¬ Support

Open an issue in the repository or contact the maintainer.

---

This is a proofâ€‘ofâ€‘concept with practical, explainable detection. For higher assurance, integrate domainâ€‘specific rules, modelâ€‘based detectors, and provenance tracking.
# PoisonProof AI - Dataset Integrity Verification System

A modern Flask web application that simulates a proof-of-concept for AI integrity verification. The system detects potential data poisoning attacks in machine learning datasets through advanced anomaly detection and cryptographic verification.

## ðŸš€ Features

- **Modern Web Interface**: Clean, responsive design using Bootstrap 5
- **File Upload System**: Support for CSV and image datasets (PNG, JPG, JPEG, GIF, BMP)
- **Anomaly Detection**: Real detection for CSVs using robust statistics (MAD-based z-scores and IQR) and image checks via Error Level Analysis (ELA) and blur metrics
- **Cryptographic Verification**: SHA-256 hashing for dataset integrity verification
- **Visual Analytics**: Interactive charts showing anomaly distribution
- **Real-time Processing**: Loading indicators and progress tracking
- **Security Features**: File validation, secure upload handling, and data cleanup

## ðŸ› ï¸ Technology Stack

- **Backend**: Flask (Python)
- **Frontend**: Bootstrap 5, HTML5, CSS3, JavaScript
- **Data Processing**: Pandas, NumPy, Pillow
- **Visualization**: Plotly.js
- **Security**: Werkzeug, SHA-256 hashing

## ðŸ“‹ Prerequisites

- Python 3.8 or higher
- pip (Python package installer)

## ðŸ”§ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/joedanields/PoisonProof-AI.git
   cd PoisonProof-AI
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## ðŸš€ Quick Start

1. **Run the application**
   ```bash
   python run.py
   ```
   Or use Flask's built-in command:
   ```bash
   python app.py
   ```

2. **Access the application**
   Open your web browser and navigate to: `http://127.0.0.1:5000`

## ðŸ“ Project Structure

```
PoisonProof-AI/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ config.py             # Configuration settings
â”œâ”€â”€ run.py                # Application runner script
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ templates/            # HTML templates
â”‚   â”œâ”€â”€ base.html        # Base template with navbar/footer
â”‚   â”œâ”€â”€ index.html       # Landing page
â”‚   â”œâ”€â”€ upload.html      # File upload page
â”‚   â””â”€â”€ results.html     # Scan results page
â”œâ”€â”€ static/              # Static assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css    # Custom styles
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ main.js      # JavaScript functionality
â”œâ”€â”€ uploads/             # Temporary file storage (auto-created)
â””â”€â”€ README.md           # This file
```

## ðŸŽ¯ Usage

### 1. Landing Page
- Overview of AI integrity challenges
- Feature descriptions and benefits
- Call-to-action to start scanning

### 2. Upload Dataset
- Drag-and-drop or click to upload files
- File validation (type and size checking)
- Supported formats: CSV, PNG, JPG, JPEG, GIF, BMP
- Maximum file size: 16MB

### 3. Scan Results
- List of detected anomalies with severity levels
- Interactive pie chart showing anomaly distribution
- SHA-256 hash for dataset verification
- Copy hash functionality for future reference

## ðŸ”’ Security Features

- **File Validation**: Strict file type and size checking
- **Secure Filenames**: Werkzeug's secure_filename for safe file handling
- **Temporary Storage**: Files are automatically deleted after processing
- **Hash Verification**: SHA-256 cryptographic hashing for integrity
- **CSRF Protection**: Built-in Flask security features

## ðŸŽ¨ UI Components

### Color Coding
- **High Severity**: Red (Immediate attention required)
- **Medium Severity**: Yellow (Review recommended)
- **Low Severity**: Green (Minor concern)

### Interactive Elements
- Loading spinners during processing
- Progress indicators
- Hover effects on cards and buttons
- Responsive design for mobile devices

## âš™ï¸ Configuration

The application supports multiple environments through `config.py`:

- **Development**: Debug mode enabled, detailed error messages
- **Production**: Security hardened, optimized for deployment
- **Testing**: Configured for automated testing

## ðŸ§ª Simulated Anomaly Detection
The application uses lightweight, real anomaly identification methods without heavy ML dependencies:

### CSV Files (tabular)
- Robust z-score using Median Absolute Deviation (MAD)
- IQR (interquartile range) fences per numeric column
- Per-row aggregation into severity + confidence
   - Tunables in `app.py`: z-score threshold (3.5), IQR factor (1.5), max results (50)

### Image Files
- Error Level Analysis (ELA) to flag potential edits/recompression
- Blur/texture check via gradient variance
- Dynamic range check for over-compression/washed-out images

These can be tuned in `app.py` inside `_detect_csv_anomalies` and `_analyze_image`.

## ðŸš€ Deployment

### Local Development
```bash
export FLASK_ENV=development
python run.py
```

### Production Deployment
```bash
export FLASK_ENV=production
export SECRET_KEY=your-secure-secret-key
python run.py
```

## ðŸ”„ Future Enhancements

- Real anomaly detection algorithms
- Machine learning model integration
- Database storage for scan history
- User authentication and authorization
- API endpoints for programmatic access
- Advanced visualization options
- Batch processing capabilities

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- Bootstrap team for the excellent CSS framework
- Plotly.js for interactive visualizations
- Flask community for the robust web framework
- Open source community for inspiration and tools

## ðŸ“ž Support

For support, email [joedanielajd@gmail.com] or create an issue in the GitHub repository.

---

