# PoisonProof AI - Dataset Integrity Verification System

A modern Flask web application that simulates a proof-of-concept for AI integrity verification. The system detects potential data poisoning attacks in machine learning datasets through advanced anomaly detection and cryptographic verification.

## ğŸš€ Features

- **Modern Web Interface**: Clean, responsive design using Bootstrap 5
- **File Upload System**: Support for CSV and image datasets (PNG, JPG, JPEG, GIF, BMP)
- **Anomaly Detection**: Simulated scanning for suspicious patterns and outliers
- **Cryptographic Verification**: SHA-256 hashing for dataset integrity verification
- **Visual Analytics**: Interactive charts showing anomaly distribution
- **Real-time Processing**: Loading indicators and progress tracking
- **Security Features**: File validation, secure upload handling, and data cleanup

## ğŸ› ï¸ Technology Stack

- **Backend**: Flask (Python)
- **Frontend**: Bootstrap 5, HTML5, CSS3, JavaScript
- **Data Processing**: Pandas, NumPy, Pillow
- **Visualization**: Plotly.js
- **Security**: Werkzeug, SHA-256 hashing

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- pip (Python package installer)

## ğŸ”§ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/joedanields/PoisonProof-AI.git
   cd PoisonProof-AI
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸš€ Quick Start

1. **Run the application**
   ```bash
   python run.py
   ```
   Or use Flask's built-in command:
   ```bash
   python app.py
   ```

2. **Access the application**
   Open your web browser and navigate to: `http://127.0.0.1:5000`

## ğŸ“ Project Structure

```
PoisonProof-AI/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ config.py             # Configuration settings
â”œâ”€â”€ run.py                # Application runner script
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ templates/            # HTML templates
â”‚   â”œâ”€â”€ base.html        # Base template with navbar/footer
â”‚   â”œâ”€â”€ index.html       # Landing page
â”‚   â”œâ”€â”€ upload.html      # File upload page
â”‚   â””â”€â”€ results.html     # Scan results page
â”œâ”€â”€ static/              # Static assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css    # Custom styles
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ main.js      # JavaScript functionality
â”œâ”€â”€ uploads/             # Temporary file storage (auto-created)
â””â”€â”€ README.md           # This file
```

## ğŸ¯ Usage

### 1. Landing Page
- Overview of AI integrity challenges
- Feature descriptions and benefits
- Call-to-action to start scanning

### 2. Upload Dataset
- Drag-and-drop or click to upload files
- File validation (type and size checking)
- Supported formats: CSV, PNG, JPG, JPEG, GIF, BMP
- Maximum file size: 16MB

### 3. Scan Results
- List of detected anomalies with severity levels
- Interactive pie chart showing anomaly distribution
- SHA-256 hash for dataset verification
- Copy hash functionality for future reference

## ğŸ”’ Security Features

- **File Validation**: Strict file type and size checking
- **Secure Filenames**: Werkzeug's secure_filename for safe file handling
- **Temporary Storage**: Files are automatically deleted after processing
- **Hash Verification**: SHA-256 cryptographic hashing for integrity
- **CSRF Protection**: Built-in Flask security features

## ğŸ¨ UI Components

### Color Coding
- **High Severity**: Red (Immediate attention required)
- **Medium Severity**: Yellow (Review recommended)
- **Low Severity**: Green (Minor concern)

### Interactive Elements
- Loading spinners during processing
- Progress indicators
- Hover effects on cards and buttons
- Responsive design for mobile devices

## âš™ï¸ Configuration

The application supports multiple environments through `config.py`:

- **Development**: Debug mode enabled, detailed error messages
- **Production**: Security hardened, optimized for deployment
- **Testing**: Configured for automated testing

## ğŸ§ª Simulated Anomaly Detection

The current implementation includes simulated anomaly detection for demonstration purposes:

### CSV Files
- Random outlier detection
- Data pattern analysis simulation
- Column-wise anomaly flagging

### Image Files
- Visual manipulation detection
- Pixel-level anomaly simulation
- Adversarial pattern identification

## ğŸš€ Deployment

### Local Development
```bash
export FLASK_ENV=development
python run.py
```

### Production Deployment
```bash
export FLASK_ENV=production
export SECRET_KEY=your-secure-secret-key
python run.py
```

## ğŸ”„ Future Enhancements

- Real anomaly detection algorithms
- Machine learning model integration
- Database storage for scan history
- User authentication and authorization
- API endpoints for programmatic access
- Advanced visualization options
- Batch processing capabilities

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Bootstrap team for the excellent CSS framework
- Plotly.js for interactive visualizations
- Flask community for the robust web framework
- Open source community for inspiration and tools

## ğŸ“ Support

For support, email [joedanielajd@gmail.com] or create an issue in the GitHub repository.

---

